# KARN
AI-Powered Sign Language Translator 
It is a website designed to capture the images, using camera and then identifies the data, converting it into text format.
It is a responsive website made using React,Python,Html,CSS, and Javascript.
Several Libraries of python are used ,which include: Torch,Sklearn,Numpy,Pandas,OpenCv,Mediapipe,TensorFlow etc.


Components of Karn:
1) Input:Capturing Sign Language(Image/Video Input)
2) Processing: Ai and Machine learning
   *)Computer Vision :-The system detects the hands, fingers, and body posture
    *)Deep Learning :- AI model analyzes the gesture
   *) Natural Language Processing :-Converts Recognized signs into text
3) Output: The signs are translated into texts
   
How AI recognizes sign Language:
1) Preprocessing:- The AI uses object detection (e.g., OpenCV, Mediapipe) to track hands.
It extracts features like finger positions, angles, and motion patterns.
2) Model Training:- Data is trained using dataset created by ourselves.
3) Gesture to text Conversion:- It translates it into English

Challenges & Future Developments

üöß Challenges:
Different sign languages exist (ASL, BSL, ISL, etc.).
Continuous gestures (not just individual signs) are harder to recognize.
Requires large, diverse datasets for accuracy.

üöÄ Future Improvements:
Real-time AI processing on mobile devices.
Integration with smart glasses (AR) for real-world applications.
Multilingual support to bridge communication barriers.

Key Features of Karn:
1.) Real-time Translation
2.) AI-Powered Recognition
3.) Text Output
4.) User-Friendly Interface
5.) OpenCV and MediaPipe Integration

Use Cases:-
‚úîÔ∏è Accessibility for the Deaf & Hard of Hearing
‚úîÔ∏è Real-time translation for meetings & education
‚úîÔ∏è AI-powered sign language assistants

!!REMARKS: Python folder is in zip file karn11,being a raw file it is needed to download it before using it!
